{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "brown-chassis",
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import CalledProcessError\n",
    "import h5py\n",
    "\n",
    "from collections import OrderedDict\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from batchgenerators.augmentations.utils import pad_nd_image\n",
    "from nnunet.preprocessing.preprocessing import PreprocessorFor2D\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from brats.preprocessing.hdbet_wrapper import hd_bet\n",
    "\n",
    "import nibabel as nib\n",
    "from nibabel.processing import conform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "concrete-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "PREP_DATA_DIR = Path('/home/jupyter/data/AIBL/AIBL_dissertacao_prep')\n",
    "DATASET_FPATH = Path('/home/jupyter/data/AIBL/AIBL_slices_fix_2mm_split.hdf5')\n",
    "\n",
    "SPLIT_CSV_FPATH = Path('/home/jupyter/data/AIBL/csv_dataset_dissertacao.csv')\n",
    "\n",
    "DOWNSIZE = True\n",
    "\n",
    "tmpdir = Path('.tmpdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worst-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocess_for_nnunet(\n",
    "        img_fpath,\n",
    "        tmpdir='.tmpdir',\n",
    "        patch_size=[192, 160],\n",
    "        input_shape_must_be_divisible_by=[32, 32],\n",
    "        normalization_schemes=OrderedDict([(0, 'nonCT')]),\n",
    "        use_mask_for_norm=OrderedDict([(0, True)]),\n",
    "        transpose_forward=[0, 1, 2],\n",
    "        intensity_properties=None,\n",
    "        target_spacing=[1., 1., 1.],\n",
    "    ):\n",
    "    brain_img_fpath, _ = hd_bet(img_fpath, tmpdir, mode='fast')\n",
    "\n",
    "    prep = PreprocessorFor2D(normalization_schemes, use_mask_for_norm,\n",
    "                                transpose_forward, intensity_properties)\n",
    "    brain, _, prop = prep.preprocess_test_case([str(brain_img_fpath),], target_spacing)\n",
    "\n",
    "    # get only slices with meaningful brain info\n",
    "    crop_lb = prop['crop_bbox'][0][0]\n",
    "    lb = int(35 / target_spacing[0]) - crop_lb\n",
    "    ub = int(115 / target_spacing[0]) - crop_lb\n",
    "    brain = brain[:,lb:ub]\n",
    "\n",
    "    padded_brain, _ = pad_nd_image(\n",
    "        brain,\n",
    "        new_shape=patch_size,\n",
    "        mode='constant',\n",
    "        kwargs={'constant_values': 0},\n",
    "        return_slicer=True,\n",
    "        shape_must_be_divisible_by=input_shape_must_be_divisible_by,\n",
    "    )\n",
    "\n",
    "    return padded_brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "after-complement",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir.mkdir(exist_ok=True)\n",
    "\n",
    "target_shape = (80, 192, 160)\n",
    "\n",
    "if DOWNSIZE:\n",
    "    target_shape = (40, 96, 96)\n",
    "\n",
    "# split data\n",
    "df = pd.read_csv(SPLIT_CSV_FPATH)\n",
    "df['path'] = df['path'] + '.gz'\n",
    "test_fpaths = df.path.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "speaking-replica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nibabel.nifti1.Nifti1Image at 0x7fafd783f9d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "nib.load(\"/home/jupyter/data/AIBL/AIBL_dissertacao_prep/I1075847__80.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "numerous-black",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/data/AIBL/AIBL_dissertacao_prep/I450389__71'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_fpath.split('.nii')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "optimum-oracle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I450389__71.nii.gz'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_fpath.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "olympic-fields",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/724 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (120, 120, 77)\n",
      "affine: \n",
      "[[   2.    0.   -0. -119.]\n",
      " [   0.    2.   -0. -128.]\n",
      " [   0.    0.    2.  -67.]\n",
      " [   0.    0.    0.    1.]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [  3 120 120  77   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 2. 2. 2. 1. 1. 1. 1.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 2\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : aligned\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : -119.0\n",
      "qoffset_y       : -128.0\n",
      "qoffset_z       : -67.0\n",
      "srow_x          : [   2.    0.   -0. -119.]\n",
      "srow_y          : [   0.    2.   -0. -128.]\n",
      "srow_z          : [  0.   0.   2. -67.]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# update_dataset(test_fpaths, i_test, 'test')\n",
    "for img_fpath in tqdm(test_fpaths):\n",
    "        age = int(img_fpath.split('.nii.gz')[0].split('__')[-1])\n",
    "\n",
    "        img = nib.load(img_fpath)\n",
    "        dsz_img = conform(img, out_shape=tuple(np.array(img.shape) // 2), voxel_size=(2.,2.,2.))\n",
    "        img_fpath = tmpdir/img_fpath\n",
    "#         print(img_fpath)\n",
    "#         nib.save(dsz_img, str(img_fpath))\n",
    "        break\n",
    "print(dsz_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-marks",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    assert PREP_DATA_DIR.exists(), f\"`{PREP_DATA_DIR}` doesn't exist\"\n",
    "    assert DATASET_FPATH.parent.exists(), f\"`{DATASET_FPATH.parent}` doesn't exist\"\n",
    "\n",
    "    tmpdir.mkdir(exist_ok=True)\n",
    "\n",
    "    target_shape = (80, 192, 160)\n",
    "\n",
    "    if DOWNSIZE:\n",
    "        target_shape = (40, 96, 96)\n",
    "\n",
    "    # split data\n",
    "    df = pd.read_csv(SPLIT_CSV_FPATH)  \n",
    "    test_fpaths = df.path.unique()\n",
    "\n",
    "    i_test = 0\n",
    "\n",
    "    # create dataset\n",
    "    if DATASET_FPATH.exists():\n",
    "        # check if there's any progress already\n",
    "        with h5py.File(DATASET_FPATH, 'r') as h:\n",
    "            # overwrite the last image just to be sure\n",
    "            n_test = max((h['test']['y'].shape[0] // target_shape[0]) -1,0)\n",
    "        \n",
    "        test_fpaths = test_fpaths[n_test-1:]\n",
    "#         print('AQUI',test_fpaths[0])\n",
    "        i_test = n_test * target_shape[0]\n",
    "    else:\n",
    "        with h5py.File(DATASET_FPATH, 'w') as h:\n",
    "\n",
    "            test = h.create_group('test')\n",
    "            X_test = test.create_dataset(\n",
    "                'X',\n",
    "                (0,target_shape[1],target_shape[2]),\n",
    "                maxshape=(None,target_shape[1],target_shape[2]),\n",
    "                dtype='float32',\n",
    "                chunks=(1,target_shape[1],target_shape[2]),\n",
    "                compression='gzip',\n",
    "            )\n",
    "            y_test = test.create_dataset(\n",
    "                'y',\n",
    "                (0,),\n",
    "                maxshape=(None,),\n",
    "                dtype='uint8',\n",
    "            )\n",
    "\n",
    "    def update_dataset(imgs_fpaths, i, ds_name):\n",
    "        for img_fpath in tqdm(imgs_fpaths):\n",
    "            age = int(img_fpath.split('.nii.gz')[0].split('__')[-1])\n",
    "\n",
    "            img = nib.load(img_fpath)\n",
    "            dsz_img = conform(img, out_shape=tuple(np.array(img.shape) // 2), voxel_size=(2.,2.,2.))\n",
    "            img_fpath = tmpdir/img_fpath.name\n",
    "            nib.save(dsz_img, str(img_fpath))\n",
    "\n",
    "            try:\n",
    "                brain = load_preprocess_for_nnunet(img_fpath, patch_size=[96,80], target_spacing=[2., 2., 2.], tmpdir=str(tmpdir.resolve()))\n",
    "            except CalledProcessError:\n",
    "                print(\"WARNING!\")\n",
    "                # img_fpath.unlink()\n",
    "                continue\n",
    "\n",
    "            if brain[0].shape == target_shape:\n",
    "                with h5py.File(DATASET_FPATH, 'r+') as h:\n",
    "                    X = h[ds_name]['X']\n",
    "                    y = h[ds_name]['y']\n",
    "\n",
    "                    X.resize(i + target_shape[0], axis=0)\n",
    "                    y.resize(i + target_shape[0], axis=0)\n",
    "\n",
    "                    X[i:i+target_shape[0]] = brain[0]\n",
    "                    y[i:i+target_shape[0]] = age\n",
    "                i += target_shape[0]\n",
    "            else:\n",
    "                img_fpath.unlink()\n",
    "\n",
    "\n",
    "    print('Working on test images')\n",
    "    update_dataset(test_fpaths, i_test, 'test')"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m65"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
